{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from scipy.optimize import minimize_scalar\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGSOutput:\n",
    "    def __init__(self, x, fx, converged, iter):\n",
    "        self.x = x\n",
    "        self.fx = fx\n",
    "        self.converged = converged\n",
    "        self.iter = iter\n",
    "\n",
    "    def add_history(self,history):\n",
    "        self.history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs_step(f, df, x, search_direction, method = \"Armijo\", armijo_param = 0.5) -> float:\n",
    "    \"\"\" \n",
    "    computes BFGS step size\n",
    "\n",
    "    Parameters:\n",
    "    - f: objective function\n",
    "    - df: derivative of objective function\n",
    "    - x: current iterate\n",
    "    - method: \"full\", \"exact\" or \"Armijo\"\n",
    "    - armijo_param: Armijo parameter. Only needed if method = \"Armijo\"\n",
    "\n",
    "    returns:\n",
    "    - alpha: step size\n",
    "    \"\"\"\n",
    "    if method == \"full\":\n",
    "        return 1\n",
    "    \n",
    "    elif method == \"exact\":\n",
    "        line_search = lambda alpha: f(x + alpha*search_direction)\n",
    "        return minimize_scalar(line_search).x\n",
    "\n",
    "    elif method == \"Armijo\":\n",
    "        line_search = lambda alpha: f(x + alpha*search_direction)\n",
    "        alpha = 1\n",
    "        while line_search(alpha) > f(x) + armijo_param * alpha * np.dot(df(x), search_direction):\n",
    "            alpha *= 0.5\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(f, x0, method = \"Armijo\", armijo_param = 0.5, max_iter = 10, tol = 1e-6, save_history = False):\n",
    "\n",
    "    \"\"\" \n",
    "    Performs the BFGS optimization algorithm\n",
    "\n",
    "    Parameters:\n",
    "    - f: Objective function\n",
    "    - x0: Initial guess for x\n",
    "    - method: Method used to calculate the step size. Either \"full\", \"exact\" or \"Armaijo\" (default)\n",
    "    - armijo_param: Only needed if method=\"Armajio\" (default: 0.5)\n",
    "    - max_iter: maximum number of iterations\n",
    "    - tol: Convergence tolerance\n",
    "    - save_history: If True, iteration history is returned\n",
    "\n",
    "    returns:\n",
    "    BFGS output with attributes:\n",
    "    - x: Calculated minimizer\n",
    "    - fx: Minimal value\n",
    "    - converged: If True, method converged\n",
    "    - n_iter: Number of iterations\n",
    "    - (optional) history\n",
    "    \"\"\"\n",
    "\n",
    "    n = x0.size\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    df = grad(f) # compute the gradient of f\n",
    "    H_inv = np.eye(n) # initialize inverse Hessian\n",
    "\n",
    "    converged = False\n",
    "    n_iter = max_iter\n",
    "\n",
    "    if save_history:\n",
    "        history = []\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        if save_history:\n",
    "            history.append(x)\n",
    "        \n",
    "        if la.norm(df(x)) < tol:\n",
    "            n_iter = iter\n",
    "            converged = True\n",
    "            break\n",
    "        \n",
    "        search_direction = - H_inv @ df(x)\n",
    "        step_size = bfgs_step(f, df, x, search_direction, method = method, armijo_param = armijo_param)\n",
    "\n",
    "        #perform updates\n",
    "        x_old = x\n",
    "\n",
    "        x = x + step_size * search_direction\n",
    "\n",
    "        p = x - x_old\n",
    "        q = df(x) - df(x_old)\n",
    "        rho = 1 / np.dot(p,q)\n",
    "\n",
    "        if iter == 0:\n",
    "            # rescale first Hessian\n",
    "            H_inv *= np.dot(p,q) / np.dot(q,q)\n",
    "\n",
    "        H_inv = (np.eye(n) - rho * p @ q.T) @ H_inv @ (np.eye(n) - rho * p @ q.T)\n",
    "\n",
    "    out = BFGSOutput(x, f(x), converged, n_iter)\n",
    "    if save_history:\n",
    "        out.add_history(history)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 + x[1]** 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
