{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NODE sheet 1\n",
    "Timo Weber, Alassane Diagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "from scipy.optimize import minimize_scalar\n",
    "import scipy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFGSOutput:\n",
    "    def __init__(self, x, fx, converged, iter):\n",
    "        self.x = x\n",
    "        self.fx = fx\n",
    "        self.converged = converged\n",
    "        self.iter = iter\n",
    "\n",
    "    def add_history(self,history):\n",
    "        self.history = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs_step(f, df, x, search_direction, method = \"Armijo\", armijo_param = 0.5) -> float:\n",
    "    \"\"\" \n",
    "    computes BFGS step size\n",
    "\n",
    "    Parameters:\n",
    "    - f: objective function\n",
    "    - df: derivative of objective function\n",
    "    - x: current iterate\n",
    "    - method: \"full\", \"exact\" or \"Armijo\"\n",
    "    - armijo_param: Armijo parameter. Only needed if method = \"Armijo\"\n",
    "\n",
    "    returns:\n",
    "    - alpha: step size\n",
    "    \"\"\"\n",
    "    if method == \"full\":\n",
    "        return 1\n",
    "    \n",
    "    elif method == \"exact\":\n",
    "        line_search = lambda alpha: f(x + alpha*search_direction)\n",
    "        return minimize_scalar(line_search).x\n",
    "\n",
    "    elif method == \"Armijo\":\n",
    "        line_search = lambda alpha: f(x + alpha*search_direction)\n",
    "        alpha = 1\n",
    "        while line_search(alpha) > f(x) + armijo_param * alpha * np.dot(df(x), search_direction):\n",
    "            alpha *= 0.5\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfgs(f, x0, method = \"Armijo\", armijo_param = 0.5, max_iter = 20, tol = 1e-5, save_history = False):\n",
    "\n",
    "    \"\"\" \n",
    "    Performs the BFGS optimization algorithm\n",
    "\n",
    "    Parameters:\n",
    "    - f: Objective function\n",
    "    - x0: Initial guess for x\n",
    "    - method: Method used to calculate the step size. Either \"full\", \"exact\" or \"Armaijo\" (default)\n",
    "    - armijo_param: Only needed if method=\"Armajio\" (default: 0.5)\n",
    "    - max_iter: maximum number of iterations\n",
    "    - tol: Convergence tolerance\n",
    "    - save_history: If True, iteration history is returned\n",
    "\n",
    "    returns:\n",
    "    BFGS output with attributes:\n",
    "    - x: Calculated minimizer\n",
    "    - fx: Minimal value\n",
    "    - converged: If True, method converged\n",
    "    - n_iter: Number of iterations\n",
    "    - (optional) history\n",
    "    \"\"\"\n",
    "\n",
    "    n = x0.size\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    df = grad(f) # compute the gradient of f\n",
    "    H_inv = np.eye(n) # initialize inverse Hessian\n",
    "\n",
    "    converged = False\n",
    "    n_iter = max_iter\n",
    "\n",
    "    if save_history:\n",
    "        history = []\n",
    "    \n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        if save_history:\n",
    "            history.append(x)\n",
    "        \n",
    "        if la.norm(df(x)) < tol:\n",
    "            n_iter = iter\n",
    "            converged = True\n",
    "            break\n",
    "        \n",
    "        search_direction = - H_inv @ df(x)\n",
    "        step_size = bfgs_step(f, df, x, search_direction, method = method, armijo_param = armijo_param)\n",
    "\n",
    "        #perform updates\n",
    "        x_old = x\n",
    "\n",
    "        x = x + step_size * search_direction\n",
    "\n",
    "        p = x - x_old\n",
    "        q = df(x) - df(x_old)\n",
    "        rho = 1 / np.dot(p,q)\n",
    "\n",
    "        if iter == 0:\n",
    "            # rescale first Hessian\n",
    "            H_inv *= np.dot(p,q) / np.dot(q,q)\n",
    "\n",
    "        H_inv = (np.eye(n) - rho * p @ q.T) @ H_inv @ (np.eye(n) - rho * p @ q.T)\n",
    "\n",
    "    out = BFGSOutput(x, f(x), converged, n_iter)\n",
    "    if save_history:\n",
    "        out.add_history(history)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0]**2 + x[1]** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from measurements.dat\n",
    "measurements = []\n",
    "with open('measurements.dat', 'r') as file:\n",
    "    for line in file:\n",
    "        measurements.append((line.strip().split(\"  \")))\n",
    "\n",
    "measurements = np.array(measurements).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def func(x):\n",
    "\n",
    "    def y(t,x):\n",
    "        return x[2] * np.exp(-(t-x[0])**2 / x[1])\n",
    "    \n",
    "    val = 0\n",
    "    ts = measurements[:,0]\n",
    "    ys = measurements[:,1]\n",
    "    val = np.array([(y(ts[i],x) - ys[i])**2 for i in range(len(ts))], dtype='d')\n",
    "\n",
    "    return np.sum(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kf/2r_v79wn3v1g_w1ngzsh6vlm0000gn/T/ipykernel_44045/502937074.py:10: RuntimeWarning: overflow encountered in scalar power\n",
      "  val = np.array([(y(ts[i],x) - ys[i])**2 for i in range(len(ts))], dtype='d')\n",
      "/Users/alassanediagne/miniconda3/envs/MachineLearning/lib/python3.12/site-packages/autograd/tracer.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Users/alassanediagne/miniconda3/envs/MachineLearning/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2473: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  tmp2 = (x - v) * (fx - fw)\n",
      "/var/folders/kf/2r_v79wn3v1g_w1ngzsh6vlm0000gn/T/ipykernel_44045/2276039243.py:57: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  rho = 1 / np.dot(p,q)\n",
      "/var/folders/kf/2r_v79wn3v1g_w1ngzsh6vlm0000gn/T/ipykernel_44045/2276039243.py:63: RuntimeWarning: invalid value encountered in multiply\n",
      "  H_inv = (np.eye(n) - rho * p @ q.T) @ H_inv @ (np.eye(n) - rho * p @ q.T)\n"
     ]
    }
   ],
   "source": [
    "result = bfgs(func, np.ones(3), tol=1e-3, method=\"exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "machinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
